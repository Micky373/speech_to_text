{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling and Deployment using MLOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import wave\n",
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading scripts\n",
    "sys.path.insert(1, '../scripts')\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\".\")\n",
    "\n",
    "from data_cleaning import DataCleaner\n",
    "from data_viz import Data_Viz\n",
    "\n",
    "DC = DataCleaner(\"../logs/preprocessing_notebook.log\")\n",
    "DV = Data_Viz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training set: 797\n",
      "Size of the validation set: 199\n"
     ]
    }
   ],
   "source": [
    "# loading datasets\n",
    "train_meta = DC.meta_loader(\"../data/train_meta.csv\", \"csv\")\n",
    "valid_meta = DC.meta_loader(\"../data/test_meta.csv\", \"csv\")\n",
    "\n",
    "print(f\"Size of the training set: {len(train_meta)}\")\n",
    "print(f\"Size of the validation set: {len(valid_meta)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'በ ናዝሬት ከተማ የ ሚገኘው የ ሞያ ና ቴክኒክ ኮሌጅ ተማሪዎች ካለፈ ው ሰኞ ጀምሮ አድማ በ መምታት ትምህርት ማቋረጣ ቸውን ከ ስፍራው የደረሰ ን ዘገባ ያስረዳ ል'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta[\"Target\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing | Prepare the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The set of characters accepted in the transcription.\n",
    "characters = \"\"\"\n",
    "ሀ ሁ ሂ ሄ ህ ሆ\n",
    "ለ ሉ ሊ ላ ሌ ል ሎ ሏ\n",
    "መ ሙ ሚ ማ ሜ ም ሞ ሟ\n",
    "ረ ሩ ሪ ራ ሬ ር ሮ ሯ\n",
    "ሰ ሱ ሲ ሳ ሴ ስ ሶ ሷ\n",
    "ሸ ሹ ሺ ሻ ሼ ሽ ሾ ሿ\n",
    "ቀ ቁ ቂ ቃ ቄ ቅ ቆ ቋ\n",
    "በ ቡ ቢ ባ ቤ ብ ቦ ቧ\n",
    "ቨ ቩ ቪ ቫ ቬ ቭ ቮ ቯ\n",
    "ተ ቱ ቲ ታ ቴ ት ቶ ቷ\n",
    "ቸ ቹ ቺ ቻ ቼ ች ቾ ቿ\n",
    "ኋ\n",
    "ነ ኑ ኒ ና ኔ ን ኖ ኗ\n",
    "ኘ ኙ ኚ ኛ ኜ ኝ ኞ ኟ\n",
    "አ ኡ ኢ ኤ እ ኦ\n",
    "ኧ\n",
    "ከ ኩ ኪ ካ ኬ ክ ኮ\n",
    "ኳ\n",
    "ወ ዉ ዊ ዋ ዌ ው ዎ\n",
    "ዘ ዙ ዚ ዛ ዜ ዝ ዞ ዟ\n",
    "ዠ ዡ ዢ ዣ ዤ ዥ ዦ ዧ\n",
    "የ ዩ ዪ ያ ዬ ይ ዮ\n",
    "ደ ዱ ዲ ዳ ዴ ድ ዶ ዷ\n",
    "ጀ ጁ ጂ ጃ ጄ ጅ ጆ ጇ\n",
    "ገ ጉ ጊ ጋ ጌ ግ ጐ ጓ ጔ\n",
    "ጠ ጡ ጢ ጣ ጤ ጥ ጦ ጧ\n",
    "ጨ ጩ ጪ ጫ ጬ ጭ ጮ ጯ\n",
    "ጰ ጱ ጲ ጳ ጴ ጵ ጶ ጷ\n",
    "ፀ ፁ ፂ ፃ ፄ ፅ ፆ ፇ\n",
    "ፈ ፉ ፊ ፋ ፌ ፍ ፎ ፏ\n",
    "ፐ ፑ ፒ ፓ ፔ ፕ ፖ\n",
    "\"\"\".replace('\\n',' ').split(' ')\n",
    "characters = characters[:-1]\n",
    "characters.insert(1,' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is: ['', ' ', 'ሀ', 'ሁ', 'ሂ', 'ሄ', 'ህ', 'ሆ', 'ለ', 'ሉ', 'ሊ', 'ላ', 'ሌ', 'ል', 'ሎ', 'ሏ', 'መ', 'ሙ', 'ሚ', 'ማ', 'ሜ', 'ም', 'ሞ', 'ሟ', 'ረ', 'ሩ', 'ሪ', 'ራ', 'ሬ', 'ር', 'ሮ', 'ሯ', 'ሰ', 'ሱ', 'ሲ', 'ሳ', 'ሴ', 'ስ', 'ሶ', 'ሷ', 'ሸ', 'ሹ', 'ሺ', 'ሻ', 'ሼ', 'ሽ', 'ሾ', 'ሿ', 'ቀ', 'ቁ', 'ቂ', 'ቃ', 'ቄ', 'ቅ', 'ቆ', 'ቋ', 'በ', 'ቡ', 'ቢ', 'ባ', 'ቤ', 'ብ', 'ቦ', 'ቧ', 'ቨ', 'ቩ', 'ቪ', 'ቫ', 'ቬ', 'ቭ', 'ቮ', 'ቯ', 'ተ', 'ቱ', 'ቲ', 'ታ', 'ቴ', 'ት', 'ቶ', 'ቷ', 'ቸ', 'ቹ', 'ቺ', 'ቻ', 'ቼ', 'ች', 'ቾ', 'ቿ', 'ኋ', 'ነ', 'ኑ', 'ኒ', 'ና', 'ኔ', 'ን', 'ኖ', 'ኗ', 'ኘ', 'ኙ', 'ኚ', 'ኛ', 'ኜ', 'ኝ', 'ኞ', 'ኟ', 'አ', 'ኡ', 'ኢ', 'ኤ', 'እ', 'ኦ', 'ኧ', 'ከ', 'ኩ', 'ኪ', 'ካ', 'ኬ', 'ክ', 'ኮ', 'ኳ', 'ወ', 'ዉ', 'ዊ', 'ዋ', 'ዌ', 'ው', 'ዎ', 'ዘ', 'ዙ', 'ዚ', 'ዛ', 'ዜ', 'ዝ', 'ዞ', 'ዟ', 'ዠ', 'ዡ', 'ዢ', 'ዣ', 'ዤ', 'ዥ', 'ዦ', 'ዧ', 'የ', 'ዩ', 'ዪ', 'ያ', 'ዬ', 'ይ', 'ዮ', 'ደ', 'ዱ', 'ዲ', 'ዳ', 'ዴ', 'ድ', 'ዶ', 'ዷ', 'ጀ', 'ጁ', 'ጂ', 'ጃ', 'ጄ', 'ጅ', 'ጆ', 'ጇ', 'ገ', 'ጉ', 'ጊ', 'ጋ', 'ጌ', 'ግ', 'ጐ', 'ጓ', 'ጔ', 'ጠ', 'ጡ', 'ጢ', 'ጣ', 'ጤ', 'ጥ', 'ጦ', 'ጧ', 'ጨ', 'ጩ', 'ጪ', 'ጫ', 'ጬ', 'ጭ', 'ጮ', 'ጯ', 'ጰ', 'ጱ', 'ጲ', 'ጳ', 'ጴ', 'ጵ', 'ጶ', 'ጷ', 'ፀ', 'ፁ', 'ፂ', 'ፃ', 'ፄ', 'ፅ', 'ፆ', 'ፇ', 'ፈ', 'ፉ', 'ፊ', 'ፋ', 'ፌ', 'ፍ', 'ፎ', 'ፏ', 'ፐ', 'ፑ', 'ፒ', 'ፓ', 'ፔ', 'ፕ', 'ፖ'] (size =222)\n"
     ]
    }
   ],
   "source": [
    "# Mapping characters to integers\n",
    "char_to_num = keras.layers.StringLookup(vocabulary=characters, oov_token=\"\")\n",
    "# Mapping integers back to original characters\n",
    "num_to_char = keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
    "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is to create function that describes the transformation to apply to each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Target</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Output</th>\n",
       "      <th>Duration</th>\n",
       "      <th>n_channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>በ ናዝሬት ከተማ የ ሚገኘው የ ሞያ ና ቴክኒክ ኮሌጅ ተማሪዎች ካለፈ ው ...</td>\n",
       "      <td>../data/train/wav/tr_1026_tr11027.wav</td>\n",
       "      <td>../data/train_new/tr_1026_tr11027.wav</td>\n",
       "      <td>12.16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ዘመናዊ ውን የ አምሪ ካን ሂ ዎት ሲ ቀጭ ከርሞ ጰጰሰ ይ ሉናል</td>\n",
       "      <td>../data/train/wav/tr_10603_tr04117.wav</td>\n",
       "      <td>../data/train_new/tr_10603_tr04117.wav</td>\n",
       "      <td>5.12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>እ ብዱ አስፋልቱ ላይ የ ኰለኰ ለ ው ድንጋይ መኪና አላ ሳልፍ አለ</td>\n",
       "      <td>../data/train/wav/tr_10521_tr53129.wav</td>\n",
       "      <td>../data/train_new/tr_10521_tr53129.wav</td>\n",
       "      <td>4.48</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             Target  \\\n",
       "0           0  በ ናዝሬት ከተማ የ ሚገኘው የ ሞያ ና ቴክኒክ ኮሌጅ ተማሪዎች ካለፈ ው ...   \n",
       "1           1           ዘመናዊ ውን የ አምሪ ካን ሂ ዎት ሲ ቀጭ ከርሞ ጰጰሰ ይ ሉናል   \n",
       "2           2         እ ብዱ አስፋልቱ ላይ የ ኰለኰ ለ ው ድንጋይ መኪና አላ ሳልፍ አለ   \n",
       "\n",
       "                                  Feature  \\\n",
       "0   ../data/train/wav/tr_1026_tr11027.wav   \n",
       "1  ../data/train/wav/tr_10603_tr04117.wav   \n",
       "2  ../data/train/wav/tr_10521_tr53129.wav   \n",
       "\n",
       "                                   Output  Duration  n_channel  \n",
       "0   ../data/train_new/tr_1026_tr11027.wav     12.16          2  \n",
       "1  ../data/train_new/tr_10603_tr04117.wav      5.12          2  \n",
       "2  ../data/train_new/tr_10521_tr53129.wav      4.48          2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ../data/train_new/tr_1026_tr11027.wav\n",
       "1       ../data/train_new/tr_10603_tr04117.wav\n",
       "2       ../data/train_new/tr_10521_tr53129.wav\n",
       "3       ../data/train_new/tr_10633_tr04147.wav\n",
       "4      ../data/train_new/tr_10245_tr099087.wav\n",
       "                        ...                   \n",
       "792    ../data/train_new/tr_10170_tr099012.wav\n",
       "793    ../data/train_new/tr_10295_tr100017.wav\n",
       "794    ../data/train_new/tr_10193_tr099035.wav\n",
       "795    ../data/train_new/tr_10301_tr100023.wav\n",
       "796     ../data/train_new/tr_10537_tr53145.wav\n",
       "Name: Output, Length: 797, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_meta[\"Output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/train/wav/tr_1026_tr11027.wav'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_file = train_meta[\"Feature\"][0]\n",
    "wav_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An integer scalar Tensor. The window length in samples.\n",
    "frame_length = 256 #this should be less than or equal to fft length\n",
    "# An integer scalar Tensor. The number of samples to step.\n",
    "frame_step = 160\n",
    "# An integer scalar Tensor. The size of the FFT to apply.\n",
    "# If not provided, uses the smallest power of 2 enclosing frame_length.\n",
    "fft_length = 256\n",
    "# data =  wave.open('../data/train_new/tr_10707_tr03124.wav')\n",
    "def encode_single_sample(wav_file, label):\n",
    "    \"\"\"\n",
    "    Process the Audio\n",
    "    \n",
    "    \"\"\"\n",
    "    #read wav file\n",
    "    file = tf.io.read_file(wav_file)\n",
    "    #decode voice file\n",
    "    audio, _ =tf.audio.decode_wav(file)\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    #change type to float32\n",
    "    audio = tf.cast(audio, tf.float32)    \n",
    "    #get the spectrogram\n",
    "    spectrogram = tf.signal.stft(audio, frame_length=frame_length, frame_step=frame_step, fft_length=fft_length)\n",
    "    #we only need the magnitude of the spectrogram\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.math.pow(spectrogram, 0.5)\n",
    "    #normalization\n",
    "    means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n",
    "    stddevs= tf.math.reduce_std(spectrogram, 1, keepdims=True)\n",
    "    spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
    "    \"\"\"\n",
    "    Process the label\n",
    "    \"\"\"\n",
    "    #convert label to lower case\n",
    "    label = tf.strings.lower(label)\n",
    "    #split label\n",
    "    label = tf.strings.unicode_split(label, input_encoding=\"UTF-8\")\n",
    "    # Map the characters in label to numbers\n",
    "    label = char_to_num(label)\n",
    "    #  Return a dict as our model is expecting two inputs\n",
    "    return spectrogram, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Target</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Output</th>\n",
       "      <th>Duration</th>\n",
       "      <th>n_channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>797</td>\n",
       "      <td>ካድሬው እዚህ ነው ያለው ማእከላዊ ኮሚቴው ም እዚህ ይገኛል</td>\n",
       "      <td>../data/train/wav/tr_1111_tr12012.wav</td>\n",
       "      <td>../data/train_new/tr_1111_tr12012.wav</td>\n",
       "      <td>5.632</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>798</td>\n",
       "      <td>አንበሳው ስጋ ስላ የ አጉረመረ መ</td>\n",
       "      <td>../data/train/wav/tr_10782_tr02105.wav</td>\n",
       "      <td>../data/train_new/tr_10782_tr02105.wav</td>\n",
       "      <td>2.944</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>799</td>\n",
       "      <td>ድህነት የማ ያልፍ መስሏቸው ም ንም ሳት በድ ለ ቸው በ ስድብ ሞለጯት ይ...</td>\n",
       "      <td>../data/train/wav/tr_10694_tr03111.wav</td>\n",
       "      <td>../data/train_new/tr_10694_tr03111.wav</td>\n",
       "      <td>9.216</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             Target  \\\n",
       "0         797              ካድሬው እዚህ ነው ያለው ማእከላዊ ኮሚቴው ም እዚህ ይገኛል   \n",
       "1         798                              አንበሳው ስጋ ስላ የ አጉረመረ መ   \n",
       "2         799  ድህነት የማ ያልፍ መስሏቸው ም ንም ሳት በድ ለ ቸው በ ስድብ ሞለጯት ይ...   \n",
       "\n",
       "                                  Feature  \\\n",
       "0   ../data/train/wav/tr_1111_tr12012.wav   \n",
       "1  ../data/train/wav/tr_10782_tr02105.wav   \n",
       "2  ../data/train/wav/tr_10694_tr03111.wav   \n",
       "\n",
       "                                   Output  Duration  n_channel  \n",
       "0   ../data/train_new/tr_1111_tr12012.wav     5.632          2  \n",
       "1  ../data/train_new/tr_10782_tr02105.wav     2.944          2  \n",
       "2  ../data/train_new/tr_10694_tr03111.wav     9.216          2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_meta.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataset Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 22\n",
    "# Define the trainig dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(train_meta[\"Feature\"]), list(train_meta[\"Target\"]))\n",
    ")\n",
    "train_dataset = (\n",
    "    train_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# Define the validation dataset\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(valid_meta[\"Feature\"]), list(valid_meta[\"Target\"]))\n",
    ")\n",
    "validation_dataset = (\n",
    "    validation_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 129), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 129), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining CTC loss function\n",
    "def CTCLoss(y_true, y_pred):\n",
    "    #compute the training-time loss value \n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DeepSpeech_2\"\n",
      "______________________________________________________________________________________________________________\n",
      " Layer (type)                                    Output Shape                                Param #          \n",
      "==============================================================================================================\n",
      " input (InputLayer)                              [(None, None, 129)]                         0                \n",
      "                                                                                                              \n",
      " expand_dim (Reshape)                            (None, None, 129, 1)                        0                \n",
      "                                                                                                              \n",
      " conv_1 (Conv2D)                                 (None, None, 65, 32)                        14464            \n",
      "                                                                                                              \n",
      " conv_1_bn (BatchNormalization)                  (None, None, 65, 32)                        128              \n",
      "                                                                                                              \n",
      " conv_1_relu (ReLU)                              (None, None, 65, 32)                        0                \n",
      "                                                                                                              \n",
      " conv_2 (Conv2D)                                 (None, None, 33, 32)                        236544           \n",
      "                                                                                                              \n",
      " conv_2_bn (BatchNormalization)                  (None, None, 33, 32)                        128              \n",
      "                                                                                                              \n",
      " conv_2_relu (ReLU)                              (None, None, 33, 32)                        0                \n",
      "                                                                                                              \n",
      " reshape (Reshape)                               (None, None, 1056)                          0                \n",
      "                                                                                                              \n",
      " bidirectional_1 (Bidirectional)                 (None, None, 10)                            31890            \n",
      "                                                                                                              \n",
      " dropout (Dropout)                               (None, None, 10)                            0                \n",
      "                                                                                                              \n",
      " bidirectional_2 (Bidirectional)                 (None, None, 10)                            510              \n",
      "                                                                                                              \n",
      " dropout_1 (Dropout)                             (None, None, 10)                            0                \n",
      "                                                                                                              \n",
      " bidirectional_3 (Bidirectional)                 (None, None, 10)                            510              \n",
      "                                                                                                              \n",
      " dropout_2 (Dropout)                             (None, None, 10)                            0                \n",
      "                                                                                                              \n",
      " bidirectional_4 (Bidirectional)                 (None, None, 10)                            510              \n",
      "                                                                                                              \n",
      " dropout_3 (Dropout)                             (None, None, 10)                            0                \n",
      "                                                                                                              \n",
      " bidirectional_5 (Bidirectional)                 (None, None, 10)                            510              \n",
      "                                                                                                              \n",
      " dense_1 (Dense)                                 (None, None, 10)                            110              \n",
      "                                                                                                              \n",
      " dense_1_relu (ReLU)                             (None, None, 10)                            0                \n",
      "                                                                                                              \n",
      " dropout_4 (Dropout)                             (None, None, 10)                            0                \n",
      "                                                                                                              \n",
      " dense (Dense)                                   (None, None, 223)                           2453             \n",
      "                                                                                                              \n",
      "==============================================================================================================\n",
      "Total params: 287,757\n",
      "Trainable params: 287,629\n",
      "Non-trainable params: 128\n",
      "______________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining our model\n",
    "def build_model(input_dim, output_dim, rnn_layers = 5, rnn_units =128):\n",
    "    #Model input\n",
    "    input_spectrogram = keras.layers.Input(shape=(None, input_dim), name=\"input\")\n",
    "    #Expand the dimensions to use 2D CNN\n",
    "    x = layers.Reshape((-1, input_dim, 1), name=\"expand_dim\")(input_spectrogram)\n",
    "    #convolutions layer 1\n",
    "    x = layers.Conv2D(filters=32, \n",
    "                      kernel_size=(11, 41), \n",
    "                      padding=\"same\", \n",
    "                      strides = [2,2],\n",
    "                      activation=\"relu\", \n",
    "                      name=\"conv_1\")(x)\n",
    "    x = layers.BatchNormalization(name=\"conv_1_bn\")(x)\n",
    "    x = layers.ReLU(name=\"conv_1_relu\")(x)\n",
    "    #convolution layer 2\n",
    "    x = layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=[11, 21],\n",
    "        strides=[1, 2],\n",
    "        padding=\"same\",\n",
    "        activation = \"relu\",\n",
    "        use_bias=False,\n",
    "        name=\"conv_2\",\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(name=\"conv_2_bn\")(x)\n",
    "    x = layers.ReLU(name=\"conv_2_relu\")(x)\n",
    "    # Reshape the resulted volume to feed the RNNs layers\n",
    "    x = layers.Reshape((-1, x.shape[-2] * x.shape[-1]))(x)\n",
    "    # RNN layers\n",
    "    for i in range(1, rnn_layers + 1):\n",
    "        recurrent = layers.GRU(\n",
    "            units=rnn_units,\n",
    "            activation=\"tanh\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            use_bias=True,\n",
    "            return_sequences=True,\n",
    "            reset_after=True,\n",
    "            name=f\"gru_{i}\",\n",
    "        )\n",
    "        x = layers.Bidirectional(\n",
    "            recurrent, name=f\"bidirectional_{i}\", merge_mode=\"concat\"\n",
    "        )(x)\n",
    "        if i < rnn_layers:\n",
    "            x = layers.Dropout(rate=0.5)(x)\n",
    "    # Dense layer\n",
    "    x = layers.Dense(units=rnn_units * 2, name=\"dense_1\")(x)\n",
    "    x = layers.ReLU(name=\"dense_1_relu\")(x)\n",
    "    x = layers.Dropout(rate=0.5)(x)\n",
    "    # Classification layer\n",
    "    output = layers.Dense(units=output_dim + 1, activation=\"softmax\")(x)\n",
    "    # Model\n",
    "    model = keras.Model(input_spectrogram, output, name=\"DeepSpeech_2\")\n",
    "    # Optimizer\n",
    "    opt = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    # Compile the model and return\n",
    "    model.compile(optimizer=opt, loss=CTCLoss)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Get the model\n",
    "model = build_model(\n",
    "    input_dim=fft_length // 2 + 1,\n",
    "    output_dim=char_to_num.vocabulary_size(),\n",
    "    rnn_units=5,\n",
    ")\n",
    "model.summary(line_length=110)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function to decode the output of the network\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    # Use greedy search. For complex tasks, you can use beam search\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
    "    # Iterate over the results and get back the text\n",
    "    output_text = []\n",
    "    for result in results:\n",
    "        result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(result)\n",
    "    return output_text\n",
    "\n",
    "\n",
    "# A callback class to output a few transcriptions during training\n",
    "class CallbackEval(keras.callbacks.Callback):\n",
    "    \"\"\"Displays a batch of outputs after every epoch.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def on_epoch_end(self, epoch: int, logs=None):\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for batch in self.dataset:\n",
    "            X, y = batch\n",
    "            batch_predictions = model.predict(X)\n",
    "            batch_predictions = decode_batch_predictions(batch_predictions)\n",
    "            predictions.extend(batch_predictions)\n",
    "            for label in y:\n",
    "                label = (\n",
    "                    tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "                )\n",
    "                targets.append(label)\n",
    "        wer_score = wer(targets, predictions)\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"Word Error Rate: {wer_score:.4f}\")\n",
    "        print(\"-\" * 100)\n",
    "        for i in np.random.randint(0, len(predictions), 2):\n",
    "            print(f\"Target    : {targets[i]}\")\n",
    "            print(f\"Prediction: {predictions[i]}\")\n",
    "            print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 12s 12s/steploss: 2801.458\n",
      "1/1 [==============================] - 13s 13s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Word Error Rate: 0.9728\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Target    : የተፈራ አተር ቀድሞ ስለ ተዘራ ቶሎ ጐመራ\n",
      "Prediction: ሁቦሜፅፑሜፅፑፅፑፅ  ን\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Target    : ይህንን ም የ አቶ ወንድሙ ን አባባል ለ ማረጋገጥ አንዳንድ ምእራባውያን ጋዜጠኞች ኢትዮጵያውያኑ ይገኙ ባቸዋል ተብሎ በሚ ገመቱ ባቸው የ አስመራ ገበያ ዎች ውስጥ ተዘዋው ረው ለ ማየት ሞክረ ዋል\n",
      "Prediction: ሁቦሜፅሜፅሜፅሜፅሜፅቦሜፅሜፅሜፅሜፅሜፅሜፅሜፅሜፅፑ\n",
      "----------------------------------------------------------------------------------------------------\n",
      "37/37 [==============================] - 1236s 31s/step - loss: 2801.4585 - val_loss: 2944.4263\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 4s 4s/step- loss: 2793.591\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Word Error Rate: 0.9728\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Target    : ጠጁ ን  መ መ  መ መ ና ሚስቱ ን ሲ ያሰቃ ያት አደረ\n",
      "Prediction: ሁጡሁፅ  ን\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Target    : አይዞ ሽ ከ ኔ ጋር ኮብል ዪ ብሎ አስ ኮብል ሎ አረገዝኩ ስት ለ ው ጊዜ አይንሽ ን ላ ፈር አላ ት\n",
      "Prediction: ሁጡሁፅ  ን\n",
      "----------------------------------------------------------------------------------------------------\n",
      "37/37 [==============================] - 874s 23s/step - loss: 2793.5913 - val_loss: 2933.7368\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 4s 4s/step- loss: 2784.362\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Word Error Rate: 0.9992\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Target    : በ ላቸው ም ነው እንዲ ህ ተ ንቆ ለ ጳ ጰ ሰ\n",
      "Prediction: መ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Target    : ዛሬ የ በላ ና ት ቀይ ወጥ ሁ ርጥ ያለች ና ት\n",
      "Prediction: መፅመ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "37/37 [==============================] - 885s 24s/step - loss: 2784.3621 - val_loss: 2920.8945\n"
     ]
    }
   ],
   "source": [
    "#defining the number of epochs\n",
    "epochs = 3\n",
    "#callback function to check transcriptions\n",
    "validation_callback = CallbackEval(validation_dataset)\n",
    "#Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[validation_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Word Error Rate: 0.9992\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Target    : ኢትዮጵያ ክርስትና የ ተቀበለችው በዛ ጔ ስርወ መንግስት ነው\n",
      "Prediction: መፅመ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Target    : በተለይ በ ተረጋጋ ሁኔታ አንቶ ኖ ቩ ድብደባ ሲ ያካሂዱ በ ፊልም መቅረ ና መረጋጋቱ ን የሚ ያሳየው ደግሞ የ ፊልሙ ጥራት መሆኑን እንዳስ ደሰታቸው ብዙዎቹ ገልዋል\n",
      "Prediction: መፅመፅመፅ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Target    : አብደላ እድሪስ ወደ ግብ እንዳይ ገቡ ታገዱ\n",
      "Prediction: መ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Target    : ት ግስት እህቷ ን ስት ጓጉ ክረ ሚ እንጂ የኔ ን አይነት ሀብል አይገዛ ልሽ ም አለ ቻት\n",
      "Prediction: መፅመ \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Target    : የ ታሰሩ ጓደኞ ቻችን ካል ተፈቱ እኔ ና ሶስት ጓደኞቼ ዊዝ ድሮ ዋል እን ሞላ ለ ን የሚ ል እምነት አለ ን\n",
      "Prediction: መፅመፅመፅመፅመፅመፅመፅመፅመፅመ \n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Let's check results on more validation samples\n",
    "predictions = []\n",
    "targets = []\n",
    "for batch in validation_dataset:\n",
    "    X, y = batch\n",
    "    batch_predictions = model.predict(X)\n",
    "    batch_predictions = decode_batch_predictions(batch_predictions)\n",
    "    predictions.extend(batch_predictions)\n",
    "    for label in y:\n",
    "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "        targets.append(label)\n",
    "wer_score = wer(targets, predictions)\n",
    "print(\"-\" * 100)\n",
    "print(f\"Word Error Rate: {wer_score:.4f}\")\n",
    "print(\"-\" * 100)\n",
    "for i in np.random.randint(0, len(predictions), 5):\n",
    "    print(f\"Target    : {targets[i]}\")\n",
    "    print(f\"Prediction: {predictions[i]}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://3de03d2f-e07a-4342-aacc-afcea6c5c8f0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://3de03d2f-e07a-4342-aacc-afcea6c5c8f0/assets\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(model, open('model.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b302cdd1e032ee910f5c889c3360c28564c92ad4f326fc3102e39fbe47faee66"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
